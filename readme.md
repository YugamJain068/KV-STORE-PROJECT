# KVStore â€“ Distributed Key-Value Store with Raft Consensus

## Overview

**KVStore** is a **distributed, fault-tolerant key-value database** built in **C++**, implementing the **Raft consensus algorithm** to maintain strong consistency across multiple nodes.  
It provides **durable, highly available storage** with **write-ahead logging (WAL)**, **snapshotting**, and **multi-threaded concurrency** â€” enabling resilient state recovery even under failures.

---

## âœ¨ Key Features

- ğŸ§  **Raft Consensus Algorithm** â€“ Leader-based consistency with majority commit rule  
- âš¡ **Automatic Leader Election** â€“ Randomized election timeouts prevent split votes  
- ğŸ” **Log Replication** â€“ Replicates write commands across all nodes before commit  
- ğŸ’¾ **Persistent State** â€“ Term, votedFor, and logs persisted to disk  
- ğŸ“¡ **TCP-based RPC** â€“ Inter-node communication via JSON-based RPCs  
- ğŸ” **Thread-Safe Operations** â€“ Uses `std::mutex` for critical section protection  
- ğŸ§± **Write-Ahead Logging (WAL)** â€“ Guarantees crash recovery and durability  
- ğŸ“· **Snapshotting & Checkpointing** â€“ Compact logs and store periodic state snapshots  
- ğŸ§­ **CLI Admin Tool** â€“ Cluster diagnostics, node term, and leader state introspection  
- ğŸ“Š **Metrics & Logging** â€“ Leader term, node role, and replication statistics  
- ğŸ§© **Multi-node Deployment** â€“ Seamless setup for 3+ nodes  
## ğŸ’» Command Reference

| **Category** | **Command** | **Description** |
|---------------|-------------|-----------------|
| **ğŸ§© Basic Commands** | `PUT <key> <value>` | Add or update a key-value pair |
|  | `GET <key>` | Retrieve the value for a key |
|  | `DELETE <key>` | Delete a key from the store |
| **âš™ï¸ Advanced Formats** | `PUT --key <k> --value <v>` | Use named parameters for clarity |
|  | `PUT <key> "value with spaces"` | Support quoted values containing spaces |
| **ğŸ› ï¸ Admin Commands** | `STATUS` | Display current node and role information |
|  | `METRICS` | Show detailed performance and resource metrics |
|  | `LOGSIZE` | Show size and details of the Raft log |
|  | `SNAPSHOT` | Trigger a manual snapshot checkpoint |
|  | `LOGS [count]` | Display recent Raft log entries |
|  | `CLUSTER` | Show information about all cluster nodes |
|  | `WATCH [seconds]` | Auto-refresh and display metrics periodically |
| **ğŸ§° Utility Commands** | `HELP` or `?` | Display this command reference |
|  | `HISTORY` | Show previously executed commands |
|  | `!!` | Repeat the last executed command |
|  | `!<n>` | Repeat the *nth* command from history |
|  | `STATS` | Show network and connection statistics |
|  | `CLEAR` | Clear the terminal screen |
|  | `EXIT` | Gracefully close the client connection |

---

## ğŸ—ï¸ Architecture

### Raft Consensus Layer
- **Node Roles**: Follower, Candidate, Leader  
- **Leader Election**: Randomized election timers ensure a single leader  
- **Replication**: Leaders replicate log entries via AppendEntries RPCs  
- **Persistence**: Each node maintains `term`, `votedFor`, and full Raft logs  
- **Snapshotting**: Periodically creates compact snapshots to prevent log growth  
- **Recovery**: Restarted nodes load persisted state & snapshots automatically  

### KV Store Integration
- **Consensus-Driven Writes** â€“ All modifications go through Raft commit  
- **Read Consistency** â€“ Follows leaderâ€™s committed state  
- **Follower Redirection** â€“ Non-leaders reject writes with redirect notice  
- **Crash Recovery** â€“ WAL + Snapshot replay ensures state integrity  

---

## âš™ï¸ Build Instructions

```bash
# Clone repository
git clone https://github.com/YugamJain068/KV-STORE-PROJECT
cd kvstore_project

# Create build directory
mkdir build && cd build

# Configure with CMake (Debug mode)
cmake -DCMAKE_BUILD_TYPE=Debug ..

# Build project
make
```

---

## ğŸš€ Running the Distributed Cluster

### Option 1: Automated 3-Node Cluster
```bash
# Launch 3 Raft nodes on ports 5000, 5001, and 5002
./kvstore
```

### Option 2: Manual Startup
```bash
# Terminal 1 - Node 0
./kvstore --node-id 0 --port 5000 --peers 5001,5002

# Terminal 2 - Node 1
./kvstore --node-id 1 --port 5001 --peers 5000,5002

# Terminal 3 - Node 2
./kvstore --node-id 2 --port 5002 --peers 5000,5001
```

---

## ğŸ’¬ Client Interaction

Clients can connect to any node using Netcat or telnet.  
Write operations succeed **only on the leader**.

```bash
nc localhost 5000
PUT key1 value1
GET key1
DELETE key1
EXIT
```

### Sample Output
```bash
# On leader node
PUT key1 value1  â†’ key1 added successfully.

# On follower node
PUT key2 value2  â†’ Error: Not leader. Current leader is Node 0

GET key1  â†’ value of key1: value1
```

---

## ğŸ”„ Raft Consensus Flow

1. Client sends command (PUT/DELETE)  
2. Node checks if it is the leader  
3. Leader appends command to log  
4. Leader sends AppendEntries RPCs to followers  
5. Once majority acknowledge â†’ entry is committed  
6. Command applied to state machine (KV Store)  
7. Client receives success response  

---

## ğŸ§µ Thread Safety & Concurrency

- **Mutex Protection** â€“ Each Raft nodeâ€™s shared state guarded by `std::mutex`  
- **Threaded RPC** â€“ Each RPC runs in a separate thread  
- **Client Threads** â€“ Each connection handled concurrently  
- **Election Timers** â€“ Independent timer threads per node  
- **Snapshot Threads** â€“ Background compaction and checkpoint handling  

---

## ğŸ§ª Testing Suite

### Raft Tests
- âœ… Leader election stability  
- âœ… Log replication across nodes  
- âœ… State persistence & recovery  
- âœ… Network partitions and rejoining  

### Integration Tests
- âœ… Full client-server-consensus flow  
- âœ… Concurrent clients  
- âœ… Failure recovery (leader crash + restore)  

### KV Store Tests
- âœ… CRUD operations  
- âœ… WAL persistence & replay  
- âœ… Snapshot loading  
- âœ… Concurrency stress tests  

```bash
# Run all tests
./runTests

# Run only Raft tests
./runTests --gtest_filter="RaftClusterTest.*"
```

---

## ğŸ’½ Persistent Storage

### Raft Metadata
Each node stores persistent JSON files like:
```
RaftNode0.json
RaftNode1.json
RaftNode2.json
```
Containing:
- Current term  
- VotedFor  
- Log entries  

### Write-Ahead Log (WAL)
- Append-only file for each node  
- Replayed at startup for state recovery  

### Snapshots & Checkpointing
- Periodic state snapshots reduce log size  
- Checkpoints capture full KV state and last included index  
- Enables quick restart without full log replay  

---

## ğŸ§° CLI & Metrics

### CLI Admin Tool
```bash
STATUS
METRICS
LOGSIZE
SNAPSHOT
LOGS [count]
CLUSTER
WATCH [seconds]
```

### Metrics Logging
- Current term, leader ID, commit index  
- AppendEntries success/failure rates  
- Snapshot interval events  
- Client request counts  

---

## ğŸ”’ Fault Tolerance

### Leader Failure
- Followers detect missing heartbeats  
- Trigger new election automatically  
- State restored via persistent log  

### Network Partition
- Majority partition elects leader  
- Minority stays follower  
- When healed, logs synchronize automatically  

### Node Recovery
- Restores persisted term, log, and snapshot  
- Automatically catches up with current leader  
- No manual repair required  

---

## ğŸ§­ Development Progress

### âœ… Completed (All Phases)
| Phase | Deliverables |
|:--|:--|
| **Phase 1: Foundation (Week 1â€“2)** | Single-node KV store, WAL persistence, thread-safety, TCP server |
| **Phase 2: Raft Core (Week 3â€“6)** | Leader election, heartbeat, log replication, fault tolerance |
| **Phase 3: Advanced & Polish (Week 7â€“9)** | Snapshotting, checkpointing, CLI tool, metrics/logging, final refactor |

---

## ğŸ§± Repository Structure

```
kvstore_project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ decode_encodebase64.h/cpp   # Base64 encoding/decoding utilities for snapshots/logs
â”‚   â”œâ”€â”€ kvstore_global.h            # Global constants, enums, and utility definitions
â”‚   â”œâ”€â”€ kvstore.h/cpp               # Core key-value store logic (PUT, GET, DELETE)
â”‚   â”œâ”€â”€ log_entry.h                 # Raft log entry structure (term, index, command)
â”‚   â”œâ”€â”€ logger.h/cpp                # Centralized logging utilities
â”‚   â”œâ”€â”€ main.cpp                    # Application entry point
â”‚   â”œâ”€â”€ metrics.h                   # Metrics definitions and monitoring utilities
â”‚   â”œâ”€â”€ persist_functions.h/cpp     # Persistence helpers for Raft metadata and KV state
â”‚   â”œâ”€â”€ raft_node.h/cpp             # Raft consensus algorithm implementation
â”‚   â”œâ”€â”€ rpc_server.h/cpp            # TCP/JSON-based RPC communication between nodes
â”‚   â”œâ”€â”€ server.h/cpp                # Client-facing server for handling CRUD commands
â”‚   â”œâ”€â”€ snapshot.h/cpp              # Snapshot and checkpointing mechanism
â”‚   â””â”€â”€ wal.h/cpp                   # Write-Ahead Logging (WAL) for durability
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ raft_tests.cpp              # Unit tests for Raft election and replication
â”‚   â”œâ”€â”€ kvstore_tests.cpp           # Tests for KV operations and WAL recovery
â”‚   â”œâ”€â”€ concurrency_tests.cpp       # KVStoreConcurrencyTest for multiple threads
â”‚   â”œâ”€â”€ wal_recovery_tests.cpp      # tests for wal persistance and recovery
â”‚   â””â”€â”€ tcp_server_tests.cpp        # tests for basic CRUD in tcp server
â”‚
â”œâ”€â”€ CMakeLists.txt             # Build configuration
â””â”€â”€ README.md                  # Project documentation
```

---

## ğŸš§ Future Enhancements

- ğŸ”„ **Dynamic Membership** â€“ Add/remove nodes without restart  
- ğŸŒ **HTTP API Layer** â€“ RESTful interface for modern clients   
- ğŸ” **Dashboard UI** â€“ Real-time cluster monitoring  
- ğŸª¶ **Compression & Encryption** â€“ Secure & efficient storage  

---

## ğŸ¥ Video Demo
[![View Demo on Google Drive](assets/Screenshot%202025-11-10%20222652.png)](https://drive.google.com/drive/u/0/folders/1KWkJYHPY7rt5WFnoz_0oOhH-K5Sm6Qbc)

---

**Author:** [Yugam Jain](https://github.com/YugamJain068)  
**Language:** C++17  
**Build System:** CMake  
**Testing Framework:** GoogleTest  
**Networking:** TCP (JSON RPC)  
**Consensus Algorithm:** Raft  
